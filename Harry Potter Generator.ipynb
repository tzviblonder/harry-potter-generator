{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3e30f7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-23T02:02:57.420182Z",
     "iopub.status.busy": "2022-02-23T02:02:57.418660Z",
     "iopub.status.idle": "2022-02-23T02:03:15.670904Z",
     "shell.execute_reply": "2022-02-23T02:03:15.670267Z",
     "shell.execute_reply.started": "2022-02-23T01:34:46.207357Z"
    },
    "papermill": {
     "duration": 18.265267,
     "end_time": "2022-02-23T02:03:15.671065",
     "exception": false,
     "start_time": "2022-02-23T02:02:57.405798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding,LSTM,GRU,Dense\n",
    "from tensorflow.keras import Input\n",
    "import tensorflow_probability as tfp\n",
    "import docx\n",
    "import random\n",
    "\n",
    "filepath = '../input/harry-potter/complete_harry_potter.docx'\n",
    "\n",
    "doc = docx.Document(filepath)\n",
    "\n",
    "full_text = []\n",
    "\n",
    "for paragraph in doc.paragraphs:\n",
    "    text = paragraph.text\n",
    "    if text.isupper() == False and 'J.K. Rowling' not in text and text != '':\n",
    "        full_text.append(text)\n",
    "full_text = '\\n'.join(full_text)\n",
    "full_text = full_text.replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9847fae8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T02:03:15.765098Z",
     "iopub.status.busy": "2022-02-23T02:03:15.764088Z",
     "iopub.status.idle": "2022-02-23T02:03:21.826385Z",
     "shell.execute_reply": "2022-02-23T02:03:21.825870Z",
     "shell.execute_reply.started": "2022-02-23T01:35:05.401456Z"
    },
    "papermill": {
     "duration": 6.146957,
     "end_time": "2022-02-23T02:03:21.826517",
     "exception": false,
     "start_time": "2022-02-23T02:03:15.679560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 91 unique characters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 02:03:15.854077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-23 02:03:15.956341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-23 02:03:15.957018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-23 02:03:15.958127: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-23 02:03:15.959017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-23 02:03:15.959663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-23 02:03:15.960328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-23 02:03:17.881335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-23 02:03:17.882143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-23 02:03:17.882772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-23 02:03:17.883369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "unique_characters = sorted(set(full_text))\n",
    "vocab_size = len(unique_characters)\n",
    "print('There are {} unique characters.'.format(vocab_size))\n",
    "\n",
    "char_tokenizer = keras.layers.StringLookup(vocabulary=unique_characters)\n",
    "\n",
    "detokenizer = keras.layers.StringLookup(vocabulary=char_tokenizer.get_vocabulary(),\n",
    "                                                                  invert=True)\n",
    "\n",
    "split_text = tf.strings.unicode_split(full_text,'UTF-8')\n",
    "tokenized_text = char_tokenizer(split_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-treasure",
   "metadata": {},
   "source": [
    "### The data will be sequences of characters of a specified length (defined in the variable sequence_length). The input will be the entire sequence besides the final character, and the output is the entire sequence besides the first character. The shift variable defines how many characters are between the beginning of one sequence and the next, so a smaller shift leads to a larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99834f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T02:03:21.851345Z",
     "iopub.status.busy": "2022-02-23T02:03:21.850483Z",
     "iopub.status.idle": "2022-02-23T02:03:21.963058Z",
     "shell.execute_reply": "2022-02-23T02:03:21.962609Z",
     "shell.execute_reply.started": "2022-02-23T01:35:42.900633Z"
    },
    "papermill": {
     "duration": 0.127567,
     "end_time": "2022-02-23T02:03:21.963182",
     "exception": false,
     "start_time": "2022-02-23T02:03:21.835615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length = 131\n",
    "batch_size = 100\n",
    "shuffle_size = 100\n",
    "shift = 14\n",
    "\n",
    "def make_dataset(tokenized_text,shift=shift):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(tokenized_text)\n",
    "    dataset = dataset.window(sequence_length,\n",
    "                             shift=shift,\n",
    "                             drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(sequence_length))\n",
    "    dataset = dataset.map(lambda window: (window[:-1],window[1:]))\n",
    "    dataset = dataset.batch(batch_size,drop_remainder=True).shuffle(shuffle_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "dataset = make_dataset(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce30eb37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T02:03:21.987558Z",
     "iopub.status.busy": "2022-02-23T02:03:21.987025Z",
     "iopub.status.idle": "2022-02-23T02:04:58.313973Z",
     "shell.execute_reply": "2022-02-23T02:04:58.313512Z",
     "shell.execute_reply.started": "2022-02-23T01:27:48.595127Z"
    },
    "papermill": {
     "duration": 96.342151,
     "end_time": "2022-02-23T02:04:58.314108",
     "exception": false,
     "start_time": "2022-02-23T02:03:21.971957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of inputs and outputs:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 02:03:22.058567: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input example:\n",
      "  — dead.” Dumbledore bowed his head. Professor McGonagall gasped. “Lily and James ... I can’t believe it ... I didn’t want to beli\n",
      "\n",
      "Output example:\n",
      " — dead.” Dumbledore bowed his head. Professor McGonagall gasped. “Lily and James ... I can’t believe it ... I didn’t want to belie\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      "  Pucey was trying to get past Wood — A whistling in Harry’s ear told him the Bludger had just missed him again; he turned right ov\n",
      "\n",
      "Output example:\n",
      " Pucey was trying to get past Wood — A whistling in Harry’s ear told him the Bludger had just missed him again; he turned right ove\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " en the finest moment of your miserable life, telling Voldemort you could hand him the Potters.” Pettigrew was muttering distracted\n",
      "\n",
      "Output example:\n",
      " n the finest moment of your miserable life, telling Voldemort you could hand him the Potters.” Pettigrew was muttering distractedl\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " ow’re we going?” asked Fred, looking shaken. “Floo powder?” “No,” said Dumbledore, “Floo powder is not safe at the moment, the Net\n",
      "\n",
      "Output example:\n",
      " w’re we going?” asked Fred, looking shaken. “Floo powder?” “No,” said Dumbledore, “Floo powder is not safe at the moment, the Netw\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " es tore all along the left seam — the small spun-glass ball dropped from his pocket and before either of them could catch it, one \n",
      "\n",
      "Output example:\n",
      " s tore all along the left seam — the small spun-glass ball dropped from his pocket and before either of them could catch it, one o\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " o do whatever you like — when I have finished. I will not stop you.” Harry glared at him for a moment, then flung himself back int\n",
      "\n",
      "Output example:\n",
      "  do whatever you like — when I have finished. I will not stop you.” Harry glared at him for a moment, then flung himself back into\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      "  said Lily, and she sounded cold. “Why are you so obsessed with them anyway? Why do you care what they’re doing at night?” “I’m ju\n",
      "\n",
      "Output example:\n",
      " said Lily, and she sounded cold. “Why are you so obsessed with them anyway? Why do you care what they’re doing at night?” “I’m jus\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " patrols inside the school from what my sources tell me. The place has never been so heavily guarded. How you expect to do anything\n",
      "\n",
      "Output example:\n",
      " atrols inside the school from what my sources tell me. The place has never been so heavily guarded. How you expect to do anything \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Examples of inputs and outputs:\\n')\n",
    "t = 16\n",
    "for batch in iter(dataset):\n",
    "    if random.randint(0,300) == 1:\n",
    "        num = random.randint(0,batch_size-1)\n",
    "        input_example = tf.strings.reduce_join(detokenizer(batch[0][num]),\n",
    "                                             axis=-1).numpy().decode()\n",
    "        output_example = tf.strings.reduce_join(detokenizer(batch[1][num]),\n",
    "                                             axis=-1).numpy().decode()\n",
    "        print('Input example:\\n',input_example)\n",
    "        print('\\nOutput example:\\n',output_example)\n",
    "        print('-'*40)\n",
    "        print('-'*40)\n",
    "        print()\n",
    "        t += 1\n",
    "    if t==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-converter",
   "metadata": {},
   "source": [
    "### The model embeds the text in a 300-dimensional space and passes it through two LSTM layers and one GRU layer. The cell state and hidden state are kept from one LSTM to the next. To avoid the issue of repitition, instead of always choosing the most likely character, the model learns a multinomial distribution and draws samples from it, so that a single input will not always produce the same output. With the model output being a probability distribution, the loss function is the negative log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4db4d35f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T02:04:58.349926Z",
     "iopub.status.busy": "2022-02-23T02:04:58.349127Z",
     "iopub.status.idle": "2022-02-23T02:05:00.066441Z",
     "shell.execute_reply": "2022-02-23T02:05:00.066887Z",
     "shell.execute_reply.started": "2022-02-23T01:37:12.469184Z"
    },
    "papermill": {
     "duration": 1.740997,
     "end_time": "2022-02-23T02:05:00.067106",
     "exception": false,
     "start_time": "2022-02-23T02:04:58.326109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 02:04:59.856084: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    27600       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, 300)    1200        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape (TFOpLambda) (3,)                 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici ()                   0           tf.compat.v1.shape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.zeros (TFOpLambda)           (None, 800)          0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.zeros_1 (TFOpLambda)         (None, 800)          0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, None, 800),  3523200     embedding[0][0]                  \n",
      "                                                                 tf.zeros[0][0]                   \n",
      "                                                                 tf.zeros_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 800)    3200        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 800),  5123200     batch_normalization_1[0][0]      \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 800)    3200        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       [(None, None, 800),  3844800     batch_normalization_2[0][0]      \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, 800)    3200        gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 92)     73692       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "one_hot_categorical (OneHotCate multiple             0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 12,603,292\n",
      "Trainable params: 12,597,892\n",
      "Non-trainable params: 5,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_length = len(char_tokenizer.get_vocabulary())\n",
    "embedding_dim = 300\n",
    "input_length = sequence_length - 1\n",
    "layer_size = 800\n",
    "states = None\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "inputs = keras.Input(shape=(None,))\n",
    "embedding = Embedding(input_dim=vocab_length,\n",
    "                     output_dim=embedding_dim,\n",
    "                     input_length=input_length)(inputs)\n",
    "X = keras.layers.BatchNormalization()(embedding)\n",
    "\n",
    "lstm = LSTM(layer_size,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "           return_sequences=True,\n",
    "           return_state=True)\n",
    "\n",
    "if states is None:\n",
    "    states = lstm.get_initial_state(X)\n",
    "\n",
    "X,hidden_state,cell_state = lstm(embedding,initial_state=states)\n",
    "X = keras.layers.BatchNormalization()(X)\n",
    "\n",
    "states = [hidden_state,\n",
    "          cell_state]\n",
    "X,hidden_state,cell_state = LSTM(layer_size,\n",
    "                                 return_sequences=True,\n",
    "                                 activation='relu',\n",
    "                                 kernel_initializer='he_normal',\n",
    "                                 return_state=True)(X,initial_state=states)\n",
    "X = keras.layers.BatchNormalization()(X)\n",
    "states = [hidden_state,\n",
    "          cell_state]\n",
    "X,cell_state = GRU(layer_size,\n",
    "                  return_sequences=True,\n",
    "                  return_state=True)(X,initial_state=states[1])\n",
    "X = keras.layers.BatchNormalization()(X)\n",
    "states = [hidden_state,\n",
    "         cell_state]\n",
    "X = Dense(tfpl.OneHotCategorical.params_size(vocab_length))(X)\n",
    "outputs = tfpl.OneHotCategorical(event_size=vocab_length)(X)\n",
    "\n",
    "sequence_model = keras.Model(inputs=inputs,\n",
    "                            outputs=outputs)\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "nll = lambda y_true,y_pred: -y_pred.log_prob(tf.one_hot(y_true,depth=vocab_length))\n",
    "\n",
    "sequence_model.compile(loss=nll,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "sequence_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-coverage",
   "metadata": {},
   "source": [
    "### Instead of training a set dataset on a number of epochs, the dataset is first created with a small shift size that increases after one epoch. This allows for slower, more thorough training in the beginning and quicker training towards the end. It also ensures that the data keeps changing, making the training mroe flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b74be0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T02:05:00.126697Z",
     "iopub.status.busy": "2022-02-23T02:05:00.124799Z",
     "iopub.status.idle": "2022-02-23T10:47:04.631557Z",
     "shell.execute_reply": "2022-02-23T10:47:04.631084Z"
    },
    "papermill": {
     "duration": 31324.545174,
     "end_time": "2022-02-23T10:47:04.631696",
     "exception": false,
     "start_time": "2022-02-23T02:05:00.086522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 02:05:07.689959: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4159/4159 [==============================] - 1977s 474ms/step - loss: 1.4737 - accuracy: 0.4578\n",
      "3899/3899 [==============================] - 1905s 488ms/step - loss: 1.1569 - accuracy: 0.5468\n",
      "3670/3670 [==============================] - 1779s 484ms/step - loss: 1.0772 - accuracy: 0.5739\n",
      "3466/3466 [==============================] - 1718s 495ms/step - loss: 1.0278 - accuracy: 0.5907\n",
      "3283/3283 [==============================] - 1617s 492ms/step - loss: 0.9910 - accuracy: 0.6031\n",
      "3119/3119 [==============================] - 1508s 483ms/step - loss: 0.9609 - accuracy: 0.6132\n",
      "2971/2971 [==============================] - 1454s 489ms/step - loss: 0.9351 - accuracy: 0.6217\n",
      "2836/2836 [==============================] - 1404s 494ms/step - loss: 0.9116 - accuracy: 0.6294\n",
      "2712/2712 [==============================] - 1346s 496ms/step - loss: 0.8899 - accuracy: 0.6363\n",
      "2599/2599 [==============================] - 1294s 496ms/step - loss: 0.8692 - accuracy: 0.6431\n",
      "2495/2495 [==============================] - 1242s 497ms/step - loss: 0.8496 - accuracy: 0.6493\n",
      "2399/2399 [==============================] - 1172s 488ms/step - loss: 0.8310 - accuracy: 0.6556\n",
      "2310/2310 [==============================] - 1121s 484ms/step - loss: 0.8123 - accuracy: 0.6617\n",
      "2228/2228 [==============================] - 1088s 487ms/step - loss: 0.7937 - accuracy: 0.6678\n",
      "2151/2151 [==============================] - 1061s 492ms/step - loss: 0.7766 - accuracy: 0.6735\n",
      "2079/2079 [==============================] - 1027s 493ms/step - loss: 0.7590 - accuracy: 0.6794\n",
      "2012/2012 [==============================] - 983s 487ms/step - loss: 0.7425 - accuracy: 0.6849\n",
      "1949/1949 [==============================] - 975s 499ms/step - loss: 0.7259 - accuracy: 0.6906\n",
      "1890/1890 [==============================] - 932s 492ms/step - loss: 0.7100 - accuracy: 0.6960\n",
      "1835/1835 [==============================] - 916s 498ms/step - loss: 0.6947 - accuracy: 0.7014\n",
      "1782/1782 [==============================] - 903s 504ms/step - loss: 0.6798 - accuracy: 0.7067\n",
      "1733/1733 [==============================] - 867s 499ms/step - loss: 0.6647 - accuracy: 0.7118\n",
      "1686/1686 [==============================] - 844s 499ms/step - loss: 0.6511 - accuracy: 0.7168\n",
      "1641/1641 [==============================] - 818s 495ms/step - loss: 0.6372 - accuracy: 0.7218\n",
      "1599/1599 [==============================] - 813s 506ms/step - loss: 0.6240 - accuracy: 0.7265\n"
     ]
    }
   ],
   "source": [
    "shift_sizes = np.arange(15,40)\n",
    "\n",
    "for shift in shift_sizes:\n",
    "    steps_per_epoch = int(len(full_text)/(batch_size*shift))\n",
    "    dataset = make_dataset(tokenized_text,shift=shift)\n",
    "    sequence_model.fit(dataset,\n",
    "                      steps_per_epoch=steps_per_epoch,\n",
    "                      epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4335f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T10:47:46.542784Z",
     "iopub.status.busy": "2022-02-23T10:47:46.541884Z",
     "iopub.status.idle": "2022-02-23T10:47:46.543701Z",
     "shell.execute_reply": "2022-02-23T10:47:46.544145Z",
     "shell.execute_reply.started": "2022-02-23T01:44:42.511965Z"
    },
    "papermill": {
     "duration": 20.82934,
     "end_time": "2022-02-23T10:47:46.544293",
     "exception": false,
     "start_time": "2022-02-23T10:47:25.714953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_letter(seed,model):\n",
    "    seed = seed.replace('\\n','')\n",
    "    split_seed = tf.strings.unicode_split(seed,'UTF-8')\n",
    "    tokenized_seed = char_tokenizer(split_seed)\n",
    "    expanded = tf.expand_dims(tokenized_seed,axis=0)\n",
    "    predictions = model.predict(expanded).squeeze()\n",
    "    tokens = np.argmax(predictions,axis=-1)\n",
    "    predicted_str = tf.strings.reduce_join(detokenizer(tokens),axis=-1).numpy().decode()\n",
    "    predicted_letter = predicted_str[-1]\n",
    "    return predicted_letter\n",
    "\n",
    "def generate(letters,seed,model=sequence_model):\n",
    "    for i in range(letters):\n",
    "        seed += generate_letter(seed,model)\n",
    "    return seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-preliminary",
   "metadata": {},
   "source": [
    "### The examples below are created from \"seeds\" of text that are fed into the neural network to output more characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ab51e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T10:48:28.244962Z",
     "iopub.status.busy": "2022-02-23T10:48:28.244056Z",
     "iopub.status.idle": "2022-02-23T11:22:51.673427Z",
     "shell.execute_reply": "2022-02-23T11:22:51.673923Z"
    },
    "papermill": {
     "duration": 2084.30133,
     "end_time": "2022-02-23T11:22:51.674086",
     "exception": false,
     "start_time": "2022-02-23T10:48:07.372756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He glared at Voldemort, and Scrimgeour felt nosebolt of antic beads. “If you’ve fobboned my parents,” said Dean. “Defense Against the Dark Arts. Lily toward the place together they discussed the snake that. Now?” Harry could see, intensely severe, though tremulous little elfs imbed Ron; he lay back to bed that there was a look of yawner, and he was staring at him, neither goblin soared into the shins so that he still had blasted: It appeared at the ground. They stared at eaching up to the ground in front of them, her l\n",
      "--------------------------------------------------\n",
      "\n",
      "Harry, Ron and Hermione ran up the stairs, trying not to drop the creature behind them and the clearing, a woman’s focus. “It is! You said there was only one maskey,” said Hermione. “You didn’t hear him — werewolves dead, and Kingsley and Miss Leegrow, I’m not welcome. It might have been his favorite cataster. I took this Horcruxes, she will never visit Transfigured my services when you might succeeded the arrival at Hogwarts.” Draco had begun, the Patronus disse together at this moment, then hesitated, and he groaned and bellowing at her, ready to care, those in the school, and stuffed the punch with a thick leather back. He could see now that Harry was careless for him to remain in cooling and painless. \"... as he did, but — ” For a repurt of help, but — With a dozen roave, perhaps, at breakfast in mashemaits — rought the job, he knows all about yours, who were the wrong, he found the like of Snape hottled, or of Gryffindor from what you’d call the bestfart tone, and you’ve obstailed young witches ... see ... he will never speak — ” “Professor Dumbledore’s dead,” said Ron. “We can find the snake, and don’t repair them, stuffed indulves owl aren’t determination. I must go and clatter it all.” “Look after it, but I assume that you’re talking abou\n",
      "--------------------------------------------------\n",
      "\n",
      "fought her way across to the stand where Snape stood, and was now racing along the \n",
      "row behind him; she didn’t even stop to say sorry as she knocked Professor Quirrell headfirst \n",
      "into the row in front. Reaching Snape, she crouched down, pulled out her wand. “It’s been called unheard of a second before,” said Ron vaguely; his smile faded in Dumbledore’s child, but turned pink, flickered face quivering slightly. “He already did,” said Harry at once. “Everythin’s in the Hallows?” “Ah,” said Harry, shrugging. “Just force, the boy who kept telling me to shake him,” said Harry, “but isn’t it absolutely nauseat on the bedside tower — ” “What good idiappatoon,” said Harry. “What do I enou?” “In his one, idea,” said Harry. “Thank you very much, Master,” said Ron, and Harry wondered whether breakfast had been reasonably with the group. It’s my cheek and of purer talks would mean revealing how to divide into both, what they like, I refused. It is inadvisable — how can you believe than what my wand did that’s precisely ... in this case. Drop here” — but Voldemort’s chosen pictures had filled his cupboard, after a moment or close. They were to read it to be solid. ...” Harry looked around, whether brought them checked it. “Well, yeah. We’ll never really give me preveating this much as Capon here. And you. ...” He leaned sideways into the smooth wand. “Do it, Bella, you simply searched her, I expect, getting a bit far. ...” Wormy said quickly\n",
      "--------------------------------------------------\n",
      "\n",
      "Harry gripped his wand tightly, wondering which spell would come in most useful. It’ll be your servant!” “Ron?” said Harry at once. He looked into Snape’s black hair. “Yet you have done. Let’s go this,” said Harry, “but we’ll send you a wand, so — ” “Let mess that,” snarled Rowl, falting angry. “Great theory vous,” said Ron, “you can’t save him!” snarled the loyal, disappointed elbow in her voice. “It’s me, he came back here!” Harry could still hear Neville. They looked at each other, and most of the doe fabinet them filled with golden man’s attempt: Master, he thought that Hermione could not penetrate Harry. That was why the Dark Lord won’t let me zombie! But mostly did he mean?” Hermione finished her dry. Ron gave a sumpty it bounced past him, heart pointing at the name to save him by his first day to have his body, though,” said Ron. “We’re not debated!” said Luna happily, and he and Harry stared at their doors at her lips. They spread most of their faces appeared out of nowhere: The glass walls and ceiling had slipped down from Ron’s jacket, still occur outta long friend as Transfigured attention enchanted. He lied all over the outside, looking up into snow jeerins, and whispered. “He hasn’t really got lost in our family, she’s got Potter’s aftering teether\n",
      "--------------------------------------------------\n",
      "\n",
      "Harry looked down the list and found that he was expected in Professor McGonagall’s \n",
      "office at half-past two on Monday, which would mean missing most of Divination. He and the other \n",
      "fifth years spent a considerable part of the final weekend of the Easter break reading all the \n",
      "career information that had been left there for their perusal. “Well, I don’t fancy Healing,” \n",
      "said Ron on the last evening of the holidays. He was immersed in a leaflet than living death, that Gryffindor won the Wizarding world agrees to be proud to see me. Now, listen ...” It was zigzagging. “Surely Professor Lupin was grateful as frantic, doesn’t it?” said Harry, reeling beside him. “You must follow the snake!” said Hermione, though it was impossible; he was striding acrepuffly at the old body. Ron had stooped, who had tried to put a lot closer. At last, lying in a deep water, the darkness trembled again; he leaned forward on the ground in front of him for a moment and knocked once or twice her problem safely those yellow eyes, their sharp enough words were drowned by a high-pitched, cheer voice than he had seen so many years. “You don’t think I wasn’t apathet to think, screaming and cooler and stair jogged- hunderings for Neville. With Bill’s warning it, he very odd people left Horcrux, but everything’s fine,” he told the watching to open. Panting, he could see no real them, as still as possible, as perfect, all direction like her. It roared again and Hermione unrolled them, nodded to Harry. “Dumbledore said Voldemort, I’ve got a feeling yourself!” “Well, we take order for you became a witch. I really wasn’t the only Voldemort could be in Hogsm\n",
      "--------------------------------------------------\n",
      "\n",
      "Fourteen times he made me buff up that Quidditch Cup before he was satisfied. And then \n",
      "I had another slug attack all over a Special Award for Services to the stick of nothing, defender ... accepted hundreds of years!” “No,” said Harry. “ ‘Yep, would you be alive?” asked Ron, looking frightened; he dugged me with his power, weren’t we? Every year, a tiny young man with the fact that he was torturing him until they reached the top of the stairs, while the symbol thought that he had taken Lupin — wait — Albus was a Squibbet for the Death Eaters fighting with Snape. “What — how did you get it?” McLaggen skill refused about the Granger girl. “My greatest presents!” said Harry. “Very well. Keep an eye to put it on, when you marching out and normal to you! Do you recognize the wand!” “You can’t Apparate in an army, sit down!” shouted a window at a tall witch who had worked on its back, but it did not matter. Of course, it was powerful — well, although if that would spin, would you?’ and then, kill it!” whispered Dean. Remembering her final torn sounded behind her, then said in an astonished clune of her, some awer, and his dress robes were blows asleep, heads and head told of the place. Looking toward one of the figures of Hogwarts were hanging with what looked like fire-rooming chipard burn wine. The room had lowered his wand, how unsure you’\n",
      "--------------------------------------------------\n",
      "\n",
      "Harry looked down at his History of Magic essay, his quill hanging aimlessly from his hand. \n",
      "He couldn't think of how to fill twelve inches of parchment with accounts of Goblin wars. He looked around the common\n",
      "room where a few fifth years remained huddled over their O.W.L notes near the dying fire. He put the Cloak up over her bar,” said Harry. “It was leaves, yes, is it?” “I think I can’t get us into view.” “Snake was lying,” said Xenophilius wearily, “it’s a password?” “No,” said Harry at once, “I don’t understand how I could care each other, behind heaven such ease?” “No,” said Harry. “We’re all wrong with the truth?” he whispered. “Harry, it’s wands,” he added, “I think better than to share the school,” said Harry. “That is about to tiny little trouble. A real old man who has been locked after you not to die,” Harry satrum. “But he’s made, cold as you will keep the idea of damage,” said Harry. They were completely disturbing the subject. James’s yank of Snargaluff and tingling, perhaps it was a photograph and let out a tiny wobble, less crookshanks. “Release me!” Voldemort stood up. Harry saw the deafening liquid return to her knee. Harry could feel the walls of the bodies in his voice. “That bit devastating,” said Harry firmly, “Shall cotton, he mustn’t shrugg Hagrid about his castle.” “Then let us do it at you to be — !” The tunnel Hagrid had snatched upon his parents, there was nothing where she is so suse. Please take it, and that the way Ministry wizards hurt him, n\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = \"\"\"He glared at Voldemort, \"\"\"\n",
    "generated_text = generate(500,seed)\n",
    "print(generated_text)\n",
    "print('-'*50)\n",
    "print()\n",
    "\n",
    "seed = \"\"\"Harry, Ron and Hermione ran up the stairs, trying not to drop the \"\"\"\n",
    "generated_text = generate(1200,seed)\n",
    "print(generated_text)\n",
    "print('-'*50)\n",
    "print()\n",
    "\n",
    "seed = \"\"\"fought her way across to the stand where Snape stood, and was now racing along the \n",
    "row behind him; she didn’t even stop to say sorry as she knocked Professor Quirrell headfirst \n",
    "into the row in front. Reaching Snape, she crouched down, pulled out her \"\"\"\n",
    "generated_text = generate(1200,seed)\n",
    "print(generated_text)\n",
    "print('-'*50)\n",
    "print()\n",
    "\n",
    "seed = \"\"\"Harry gripped his wand tightly, wondering which spell would come in most useful. \"\"\"\n",
    "generated_text = generate(1200,seed)\n",
    "print(generated_text)\n",
    "print('-'*50)\n",
    "print()\n",
    "\n",
    "seed = \"\"\"Harry looked down the list and found that he was expected in Professor McGonagall’s \n",
    "office at half-past two on Monday, which would mean missing most of Divination. He and the other \n",
    "fifth years spent a considerable part of the final weekend of the Easter break reading all the \n",
    "career information that had been left there for their perusal. “Well, I don’t fancy Healing,” \n",
    "said Ron on the last evening of the holidays. He was immersed in a leaflet \"\"\"\n",
    "print(generate(1200,seed))\n",
    "print('-'*50)\n",
    "print()\n",
    "\n",
    "seed = \"\"\"Fourteen times he made me buff up that Quidditch Cup before he was satisfied. And then \n",
    "I had another slug attack all over a Special Award for Services to the \"\"\"\n",
    "print(generate(1200,seed))\n",
    "print('-'*50)\n",
    "print()\n",
    "\n",
    "seed = \"\"\"Harry looked down at his History of Magic essay, his quill hanging aimlessly from his hand. \n",
    "He couldn't think of how to fill twelve inches of parchment with accounts of Goblin wars. He looked around the common\n",
    "room where a few fifth years remained huddled over their O.W.L notes near the dying fire.\"\"\"\n",
    "print(generate(1200,seed))\n",
    "print('-'*50)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1rc1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33626.443449,
   "end_time": "2022-02-23T11:23:15.525736",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-23T02:02:49.082287",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
