{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "twenty-chocolate",
   "metadata": {},
   "source": [
    "### This program creates an algorithm that \"learns\" Harry Potter in order to be able to generate new text in a similar style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3e30f7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-23T02:02:57.420182Z",
     "iopub.status.busy": "2022-02-23T02:02:57.418660Z",
     "iopub.status.idle": "2022-02-23T02:03:15.670904Z",
     "shell.execute_reply": "2022-02-23T02:03:15.670267Z",
     "shell.execute_reply.started": "2022-02-23T01:34:46.207357Z"
    },
    "papermill": {
     "duration": 18.265267,
     "end_time": "2022-02-23T02:03:15.671065",
     "exception": false,
     "start_time": "2022-02-23T02:02:57.405798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import StringLookup,Embedding,LSTM,GRU,Dense,BatchNormalization\n",
    "from tensorflow.keras import Input\n",
    "import tensorflow_probability as tfp\n",
    "import docx\n",
    "import random\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "cd = Path.cwd()\n",
    "filepath = os.path.join(cd,r'OneDrive\\Desktop\\Datasets\\complete_harry_potter.docx')\n",
    "\n",
    "doc = docx.Document(filepath)\n",
    "\n",
    "full_text = []\n",
    "\n",
    "for paragraph in doc.paragraphs:\n",
    "    text = paragraph.text\n",
    "    if text.isupper() == False and 'J.K. Rowling' not in text and text != '' and 'Page | ' not in text:\n",
    "        full_text.append(text)\n",
    "full_text = '\\n'.join(full_text)\n",
    "full_text = full_text.replace('\\n','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-henry",
   "metadata": {},
   "source": [
    "### The complete Harry Potter text is tokenized at the character level, meaning that each individual character (letter, number, punctuation, etc.) recieves its own embedding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9847fae8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T02:03:15.765098Z",
     "iopub.status.busy": "2022-02-23T02:03:15.764088Z",
     "iopub.status.idle": "2022-02-23T02:03:21.826385Z",
     "shell.execute_reply": "2022-02-23T02:03:21.825870Z",
     "shell.execute_reply.started": "2022-02-23T01:35:05.401456Z"
    },
    "papermill": {
     "duration": 6.146957,
     "end_time": "2022-02-23T02:03:21.826517",
     "exception": false,
     "start_time": "2022-02-23T02:03:15.679560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 86 unique characters. They are: [' ', '!', '\"', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '–', '—', '‘', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "unique_characters = sorted(set(full_text))\n",
    "vocab_size = len(unique_characters)\n",
    "print('There are {} unique characters. They are: '.format(vocab_size),end='')\n",
    "print(unique_characters)\n",
    "\n",
    "char_tokenizer = StringLookup(vocabulary=unique_characters)\n",
    "\n",
    "detokenizer = StringLookup(vocabulary=char_tokenizer.get_vocabulary(),\n",
    "                          invert=True)\n",
    "\n",
    "split_text = tf.strings.unicode_split(full_text,'UTF-8')\n",
    "tokenized_text = char_tokenizer(split_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-mechanics",
   "metadata": {},
   "source": [
    "### Once tokenized, the text is divided into sequences of characters (the size of which is defined by the variable sequence_length.) The sequences are then shuffled (with a seed so as to recreate the random shuffle to train on the same train dataset multiple times) and split into training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99834f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T02:03:21.851345Z",
     "iopub.status.busy": "2022-02-23T02:03:21.850483Z",
     "iopub.status.idle": "2022-02-23T02:03:21.963058Z",
     "shell.execute_reply": "2022-02-23T02:03:21.962609Z",
     "shell.execute_reply.started": "2022-02-23T01:35:42.900633Z"
    },
    "papermill": {
     "duration": 0.127567,
     "end_time": "2022-02-23T02:03:21.963182",
     "exception": false,
     "start_time": "2022-02-23T02:03:21.835615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shift = 12\n",
    "sequence_length = 301\n",
    "sequences = []\n",
    "start_point = 0\n",
    "while True:\n",
    "    sequence = tokenized_text[start_point:start_point+sequence_length]\n",
    "    sequences.append(sequence)\n",
    "    start_point += shift\n",
    "    if start_point + sequence_length >= len(tokenized_text):\n",
    "        break\n",
    "        \n",
    "sequences = np.array(sequences)\n",
    "seed = np.random.seed(100)\n",
    "np.random.shuffle(sequences)\n",
    "\n",
    "validation_size = int(len(sequences)*.03)\n",
    "train_sequences = sequences[:-validation_size]\n",
    "validation_sequences = sequences[-validation_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-accounting",
   "metadata": {},
   "source": [
    "### The training and validation sequences are turned into dataset objects in order to create a pipeline to feed into the model. This process splits each sequence into an input, which is the entire sequence besides the last letter, and an output, which is the entire sequence besides the first letter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40ab51e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T10:48:28.244962Z",
     "iopub.status.busy": "2022-02-23T10:48:28.244056Z",
     "iopub.status.idle": "2022-02-23T11:22:51.673427Z",
     "shell.execute_reply": "2022-02-23T11:22:51.673923Z"
    },
    "papermill": {
     "duration": 2084.30133,
     "end_time": "2022-02-23T11:22:51.674086",
     "exception": false,
     "start_time": "2022-02-23T10:48:07.372756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "def make_dataset(sequence_list):\n",
    "    np.random.shuffle(sequence_list)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(sequence_list)\n",
    "    dataset = dataset.map(lambda sequence: (sequence[:-1],sequence[1:]))\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = make_dataset(train_sequences)\n",
    "validation_dataset = make_dataset(validation_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-values",
   "metadata": {},
   "source": [
    "### Here are some examples of what inputs and outputs look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mounted-exposure",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of inputs and outputs:\n",
      "\n",
      "Input example:\n",
      " readful teacher she is, and how we’re not going to learn any defense from her at all,” said Hermione. “Well, what can we do about that?” said Ron, yawning. “ ’S too late, isn’t it? She got the job, she’s here to stay, Fudge’ll make sure of that.” “Well,” said Hermione tentatively. “You know, I was t\n",
      "\n",
      "Output example:\n",
      " eadful teacher she is, and how we’re not going to learn any defense from her at all,” said Hermione. “Well, what can we do about that?” said Ron, yawning. “ ’S too late, isn’t it? She got the job, she’s here to stay, Fudge’ll make sure of that.” “Well,” said Hermione tentatively. “You know, I was th\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " y. “Charms, Defense Against the Dark Arts, Herbology, Transfiguration ... all fine. I must say, I was pleased with your Transfiguration mark, Potter, very pleased. Now, why haven’t you applied to continue with Potions? I thought it was your ambition to become an Auror?” “It was, but you told me I ha\n",
      "\n",
      "Output example:\n",
      " . “Charms, Defense Against the Dark Arts, Herbology, Transfiguration ... all fine. I must say, I was pleased with your Transfiguration mark, Potter, very pleased. Now, why haven’t you applied to continue with Potions? I thought it was your ambition to become an Auror?” “It was, but you told me I had\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " nsy to a chorus of snide giggles. “Urgh, Chang, I don’t think much of your taste... At least Diggory was good-looking!” They sped up, talking and shrieking in a pointed fashion with many exaggerated glances back at Harry and Cho, leaving an embarrassed silence in their wake. Harry could think of not\n",
      "\n",
      "Output example:\n",
      " sy to a chorus of snide giggles. “Urgh, Chang, I don’t think much of your taste... At least Diggory was good-looking!” They sped up, talking and shrieking in a pointed fashion with many exaggerated glances back at Harry and Cho, leaving an embarrassed silence in their wake. Harry could think of noth\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " y happiest was Cho catching up with him as he was hurrying along to Transfiguration the next day. Before he knew what had happened her hand was in his and she was breathing in his ear, “I’m really, really sorry. That interview was so brave ...it made me cry.” He was sorry to hear she had shed even m\n",
      "\n",
      "Output example:\n",
      "  happiest was Cho catching up with him as he was hurrying along to Transfiguration the next day. Before he knew what had happened her hand was in his and she was breathing in his ear, “I’m really, really sorry. That interview was so brave ...it made me cry.” He was sorry to hear she had shed even mo\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " t and leave the corridor to Malfoy who, hopefully, would be too afraid to leave for some hours to come. He found Ron and Hermione in the Great Hall, already halfway through an early lunch. “I did it — well, kind of!” Ron told Harry enthusiastically when he caught sight of him. “I was supposed to be \n",
      "\n",
      "Output example:\n",
      "  and leave the corridor to Malfoy who, hopefully, would be too afraid to leave for some hours to come. He found Ron and Hermione in the Great Hall, already halfway through an early lunch. “I did it — well, kind of!” Ron told Harry enthusiastically when he caught sight of him. “I was supposed to be A\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " y at once with a howl of pain and Harry whirled around to face him and gasped, The Death Eater keeled over backward and his mask slipped off. It was Macnair, Buckbeak’s would-be killer, one of his eyes now swollen and bloodshot. “Thanks!” Harry said to Neville, pulling him aside as Sirius and his De\n",
      "\n",
      "Output example:\n",
      "  at once with a howl of pain and Harry whirled around to face him and gasped, The Death Eater keeled over backward and his mask slipped off. It was Macnair, Buckbeak’s would-be killer, one of his eyes now swollen and bloodshot. “Thanks!” Harry said to Neville, pulling him aside as Sirius and his Dea\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " h rather be the servant of the Malfoy boy, oh yes. ...” “That’s settled, then,” said Harry. “I’ll want regular reports, but make sure I’m not surrounded by people when you turn up. Ron and Hermione are okay. And don’t tell anyone what you’re doing. Just stick to Malfoy like a couple of wart plasters\n",
      "\n",
      "Output example:\n",
      "  rather be the servant of the Malfoy boy, oh yes. ...” “That’s settled, then,” said Harry. “I’ll want regular reports, but make sure I’m not surrounded by people when you turn up. Ron and Hermione are okay. And don’t tell anyone what you’re doing. Just stick to Malfoy like a couple of wart plasters.\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " gether,” said Neville quietly. “It was all supposed to be about fighting You-Know- Who, wasn’t it? And this is the first chance we’ve had to do something real — or was that all just a game or something?” “No — of course it wasn’t — ” said Harry impatiently. “Then we should come too,” said Neville si\n",
      "\n",
      "Output example:\n",
      " ether,” said Neville quietly. “It was all supposed to be about fighting You-Know- Who, wasn’t it? And this is the first chance we’ve had to do something real — or was that all just a game or something?” “No — of course it wasn’t — ” said Harry impatiently. “Then we should come too,” said Neville sim\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " C’mon!” Hagrid said angrily. “I’m takin’yer all back up ter school, an’ don’ let me catch yeh walkin’ down ter see me after dark again. I’m not worth that!” 7 Malfoy didn’t reappear in classes until late on Thursday morning, when the Slytherins and Gryffindors were halfway through double Potions. He\n",
      "\n",
      "Output example:\n",
      " ’mon!” Hagrid said angrily. “I’m takin’yer all back up ter school, an’ don’ let me catch yeh walkin’ down ter see me after dark again. I’m not worth that!” 7 Malfoy didn’t reappear in classes until late on Thursday morning, when the Slytherins and Gryffindors were halfway through double Potions. He \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " ents, including Lee Jordan and Hannah Abbott, standing beside another empty plinth, whose statue had concealed a secret passageway. Their wands were drawn and they were listening at the concealed hole. “Nice night for it!” Fred shouted as the castle quaked again, and Harry sprinted by, elated and te\n",
      "\n",
      "Output example:\n",
      " nts, including Lee Jordan and Hannah Abbott, standing beside another empty plinth, whose statue had concealed a secret passageway. Their wands were drawn and they were listening at the concealed hole. “Nice night for it!” Fred shouted as the castle quaked again, and Harry sprinted by, elated and ter\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " bsession . . . but it gave me strength, it cleared my mind. So, one night when they opened my door to bring food, I slipped past them as a dog. ... It’s so much harder for them to sense animal emotions that they were confused. ... I was thin, very thin . . . thin enough to slip through the bars. ...\n",
      "\n",
      "Output example:\n",
      " session . . . but it gave me strength, it cleared my mind. So, one night when they opened my door to bring food, I slipped past them as a dog. ... It’s so much harder for them to sense animal emotions that they were confused. ... I was thin, very thin . . . thin enough to slip through the bars. ... \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " lt his knees hit the cold grass. Fog was clouding his eyes. With a huge effort, he fought to remember — Sirius was innocent — innocent — We’ll be okay — I’m going to live with him — “Expecto patronum” he gasped. By the feeble light of his formless Patronus, he saw a dementor halt, very close to him.\n",
      "\n",
      "Output example:\n",
      " t his knees hit the cold grass. Fog was clouding his eyes. With a huge effort, he fought to remember — Sirius was innocent — innocent — We’ll be okay — I’m going to live with him — “Expecto patronum” he gasped. By the feeble light of his formless Patronus, he saw a dementor halt, very close to him. \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " ody said. “Your father got me out of a very tight corner a few days ago. ... Yeah, I’m staying just the one year. Special favor to Dumbledore. ... One year, and then back to my quiet retirement.” He gave a harsh laugh, and then clapped his gnarled hands together. “So — straight into it. Curses. They\n",
      "\n",
      "Output example:\n",
      " dy said. “Your father got me out of a very tight corner a few days ago. ... Yeah, I’m staying just the one year. Special favor to Dumbledore. ... One year, and then back to my quiet retirement.” He gave a harsh laugh, and then clapped his gnarled hands together. “So — straight into it. Curses. They \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      "  not wanting to appear as though he was sneaking looks at anyone else’s work, he hastily bent over his star chart and pretended to be adding notes to it while really peering over the top of the parapet toward Hagrid’s cabin. Figures were now moving across the cabin windows, temporarily blocking the \n",
      "\n",
      "Output example:\n",
      " not wanting to appear as though he was sneaking looks at anyone else’s work, he hastily bent over his star chart and pretended to be adding notes to it while really peering over the top of the parapet toward Hagrid’s cabin. Figures were now moving across the cabin windows, temporarily blocking the l\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " nd in the kitchen was certainly not troubling to do so. He snatched up his wand from his bedside table and stood facing his bedroom door, listening with all his might. Next moment he jumped as the lock gave a loud click and his door swung open. Harry stood motionless, staring through the open door a\n",
      "\n",
      "Output example:\n",
      " d in the kitchen was certainly not troubling to do so. He snatched up his wand from his bedside table and stood facing his bedroom door, listening with all his might. Next moment he jumped as the lock gave a loud click and his door swung open. Harry stood motionless, staring through the open door at\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " red by Voldemort. Or on Voldemort’s orders, more likely, I doubt Regulus was ever important enough to be killed by Voldemort in person. From what I found out after he died, he got in so far, then panicked about what he was being asked to do and tried to back out. Well, you don’t just hand in your re\n",
      "\n",
      "Output example:\n",
      " ed by Voldemort. Or on Voldemort’s orders, more likely, I doubt Regulus was ever important enough to be killed by Voldemort in person. From what I found out after he died, he got in so far, then panicked about what he was being asked to do and tried to back out. Well, you don’t just hand in your res\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " f her cage. “Dobby had to punish himself, sir,” said the elf, who had gone slightly cross-eyed. “Dobby almost spoke ill of his family, sir. ...” “Your family?” “The wizard family Dobby serves, sir. ... Dobby is a house-elf — bound to serve one house and one family forever. ...” “Do they know you’re \n",
      "\n",
      "Output example:\n",
      "  her cage. “Dobby had to punish himself, sir,” said the elf, who had gone slightly cross-eyed. “Dobby almost spoke ill of his family, sir. ...” “Your family?” “The wizard family Dobby serves, sir. ... Dobby is a house-elf — bound to serve one house and one family forever. ...” “Do they know you’re h\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " itch. With half an hour of the game gone, Gryffindor were leading sixty points to zero, Ron having made some truly spectacular saves, some by the very tips of his gloves, and Ginny having scored four of Gryffindor’s six goals. This effectively stopped Zacharias wondering loudly whether the two Weasl\n",
      "\n",
      "Output example:\n",
      " tch. With half an hour of the game gone, Gryffindor were leading sixty points to zero, Ron having made some truly spectacular saves, some by the very tips of his gloves, and Ginny having scored four of Gryffindor’s six goals. This effectively stopped Zacharias wondering loudly whether the two Weasle\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Input example:\n",
      " ainst the dark sky, here and there a window blazing fiery bright above them. The carriages jingled to a halt near the stone steps leading up to the oak front doors and Harry got out of the carriage first. He turned again to look for lit windows down by the forest, but there was definitely no sign of\n",
      "\n",
      "Output example:\n",
      " inst the dark sky, here and there a window blazing fiery bright above them. The carriages jingled to a halt near the stone steps leading up to the oak front doors and Harry got out of the carriage first. He turned again to look for lit windows down by the forest, but there was definitely no sign of \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Examples of inputs and outputs:\\n')\n",
    "t = 12\n",
    "for batch in iter(train_dataset):\n",
    "    if random.randint(0,250) == 1:\n",
    "        num = random.randint(0,batch_size-1)\n",
    "        input_example = tf.strings.reduce_join(detokenizer(batch[0][num]),\n",
    "                                             axis=-1).numpy().decode()\n",
    "        output_example = tf.strings.reduce_join(detokenizer(batch[1][num]),\n",
    "                                             axis=-1).numpy().decode()\n",
    "        print('Input example:\\n',input_example)\n",
    "        print('\\nOutput example:\\n',output_example)\n",
    "        print('-'*40)\n",
    "        print('-'*40)\n",
    "        print()\n",
    "        t += 1\n",
    "    if t==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-wright",
   "metadata": {},
   "source": [
    "### The model uses an embedding layer to embed the vocabulary (the list of characters) in a vector space, the dimensionality of which is given by the variable embedding_dim. It then uses two LSTM layers and one GRU layer (with batch normalization in between each one). The recurrent layers output the final hidden state and the cell state, as well as all hidden states for the LSTM layers. \n",
    "### All too often, text generation gets stuck in a loop, repeating a short sequences of words or characters endlessly. To solve this problem, instead of becoming a deterministic algorithm, the model learns a probability distribution. Characters are then randomly sampled from the distribution. This stochastic approch offers flexibility and randomness that enables the algorithm to avoid getting stuck in any loops. Another advantage of learning a probability distribution is that the model can use the negative log likelihood, which measures how likely the true output is given the model's weights, as a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "limiting-restaurant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 800)    69600       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, None, 800)   3200        ['embedding[0][0]']              \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLambda  (3,)                0           ['batch_normalization[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.zeros (TFOpLambda)          (None, 1200)         0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.zeros_1 (TFOpLambda)        (None, 1200)         0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, None, 1200)  9604800     ['embedding[0][0]',              \n",
      "                                , (None, 1200),                   'tf.zeros[0][0]',               \n",
      "                                 (None, 1200)]                    'tf.zeros_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, None, 1200)  4800        ['lstm[0][0]']                   \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 1200)  11524800    ['batch_normalization_1[0][0]',  \n",
      "                                , (None, 1200),                   'lstm[0][1]',                   \n",
      "                                 (None, 1200)]                    'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, None, 1200)  4800        ['lstm_1[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gru (GRU)                      [(None, None, 1200)  8647200     ['batch_normalization_2[0][0]',  \n",
      "                                , (None, 1200)]                   'lstm_1[0][2]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, None, 1200)  4800        ['gru[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 87)     104487      ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " one_hot_categorical (OneHotCat  ((None, None, 87),  0           ['dense[0][0]']                  \n",
      " egorical)                       (None, None, 87))                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,968,487\n",
      "Trainable params: 29,959,687\n",
      "Non-trainable params: 8,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_length = len(char_tokenizer.get_vocabulary())\n",
    "embedding_dim = 800\n",
    "input_length = sequence_length - 1\n",
    "layer_size = 1200\n",
    "states = None\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "inputs = keras.Input(shape=(None,))\n",
    "embedding = Embedding(input_dim=vocab_length,\n",
    "                     output_dim=embedding_dim,\n",
    "                     input_length=input_length)(inputs)\n",
    "X = BatchNormalization()(embedding)\n",
    "\n",
    "lstm = LSTM(layer_size,\n",
    "           return_sequences=True,\n",
    "           return_state=True)\n",
    "\n",
    "if states is None:\n",
    "    states = lstm.get_initial_state(X)\n",
    "\n",
    "X,hidden_state,cell_state = lstm(embedding,initial_state=states)\n",
    "X = keras.layers.BatchNormalization()(X)\n",
    "\n",
    "states = [hidden_state,\n",
    "          cell_state]\n",
    "X,hidden_state,cell_state = LSTM(layer_size,\n",
    "                                 return_sequences=True,\n",
    "                                 return_state=True)(X,initial_state=states)\n",
    "X = BatchNormalization()(X)\n",
    "states = [hidden_state,\n",
    "          cell_state]\n",
    "X,cell_state = GRU(layer_size,\n",
    "                  return_sequences=True,\n",
    "                  return_state=True)(X,initial_state=states[1])\n",
    "X = BatchNormalization()(X)\n",
    "states = [hidden_state,\n",
    "         cell_state]\n",
    "X = Dense(tfpl.OneHotCategorical.params_size(vocab_length))(X)\n",
    "outputs = tfpl.OneHotCategorical(event_size=vocab_length)(X)\n",
    "\n",
    "sequence_model = keras.Model(inputs=inputs,\n",
    "                            outputs=outputs)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "nll = lambda y_true,y_pred: -y_pred.log_prob(tf.one_hot(y_true,depth=vocab_length))\n",
    "\n",
    "sequence_model.compile(loss=nll,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "sequence_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-script",
   "metadata": {},
   "source": [
    "### The model was trained using more than 40 hours of GPU. The weights were then downloaded and uploaded here. A small sample of the validation dataset is used to evlauate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alternate-terrorist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 90s 22s/step - loss: 0.0984 - accuracy: 0.9711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09840431809425354, 0.9711328148841858]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_path = os.path.join(cd,r'OneDrive\\Desktop\\Datasets\\final-weights\\harry-potter-weights.h5')\n",
    "sequence_model.load_weights(weights_path)\n",
    "\n",
    "sample_size = 512\n",
    "test_sequences = random.sample(list(validation_sequences),sample_size)\n",
    "test_sequences = np.array(test_sequences)\n",
    "test_dataset = make_dataset(test_sequences)\n",
    "sequence_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "processed-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_letter(seed,model):\n",
    "    seed = seed.replace('\\n','')\n",
    "    split_seed = tf.strings.unicode_split(seed,'UTF-8')\n",
    "    tokenized_seed = char_tokenizer(split_seed)\n",
    "    expanded = tf.expand_dims(tokenized_seed,axis=0)\n",
    "    predictions = model.predict(expanded).squeeze()\n",
    "    tokens = np.argmax(predictions,axis=-1)\n",
    "    predicted_str = tf.strings.reduce_join(detokenizer(tokens),axis=-1).numpy().decode()\n",
    "    predicted_letter = predicted_str[-1]\n",
    "    return predicted_letter\n",
    "\n",
    "def generate(seed,num_letters=1200,model=sequence_model):\n",
    "    for i in range(num_letters):\n",
    "        seed += generate_letter(seed,model)\n",
    "    return seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-partnership",
   "metadata": {},
   "source": [
    "### Finally, the model is being tested on a number of \"seeds\", which are small bits of texts used to start the text generation. Each seed is fed into the above functions and is used to generate more text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "remarkable-greek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He glared at Voldemort, staring into his snake-like eyes. Hooded Death Eaters surriounded them, jeering \n",
      "and laughing as their master taunted and tortured Harry. “The servant died when I left his body, and I was left as weak as ever I had been,” Voldemort continued. “I returned to my hiding place far away, and I will not pretend to you that I didn’t then fear that I might never regain my powers. ... Yes, that was perhaps my darkest hour ... I could not hope that I would be sent another wizard to possess ... and I had given up hope, now, that any of my Death Eaters cared what had become of me. ...” One or two of the masked wizards in the circle moved uncomfortably, but Voldemort took no notice. “And then, not even a year ago, when I had almost abandoned hope, it happened at last ... a servant returned to me. Wormtail here, who had faked his own death to escape justice, was driven out of hiding by those he had once counted friends, and decided to return to his master. He sought me in the country where it had long been rumored I was hiding . . . helped, of course, by the rats he met along the way. Wormtail has a curious affinity with rats, do you not, Wormtail? His filthy little friends told him there was a place, deep in an Albanian forest, that they avoided, where small animals like themselves had met their deaths by a dark shadow that posse\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Harry gripped his wand tightly, wondering which spell would come in most useful. Then Voldemort did, whatever he had done any different indeed, wonderful feeling, that he could have taken to retime. The circumstances began to move as though the curtains followed him all deserted. “Stop go,” said Hermione, her eyes flashing. “Imagine a wizard buying a rusty old car and telling his wife all he wanted to do with it was take it apart to see how it worked, while really he was enchanting it to make it fly.” Mr. Weasley blinked. “Well, dear, I think you’ll find that he would be quite within the law to do that, even if — er — he maybe would have done better to, um, tell his wife the truth. ... There’s a loophole in the law, you’ll find. ... As long as he wasn’t intending to fly the car, the fact that the car could fly wouldn’t — ” “Arthur Weasley, you made sure there was a loophole when you wrote that law!” shouted Mrs. Weasley. “Just so you could carry on tinkering with all that Muggle rubbish in your shed! And for your information, Harry arrived this morning in the car you weren’t intending to fly!” “Harry?” said Mr. Weasley blankly. “Harry who?” He looked around, saw Harry, and jumped. “Good lord, is it Harry Potter? Very pleased to meet you, Ron’s told us so much a\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Harry was growing more and more frustrated by the assignment Snape had set them. How was he supposed to \n",
      "focus when he had a Goblin rebellion, a date, and a summons to the Ministry of Magic to worry about? Absentmindedly\n",
      " chewing his quill, he thought of what he might tell Sirius, and what Sirius might think. “We’ve been here allowed in, we can’t have exactly what he’s after. And I was getting close by, so what happened when he can’t speak. ...” “What is it, Dobby?” Harry said, keeping a firm hold on Dobby’s wrist to stop him from hitting himself with the water jug again. “Who’s opened it? Who opened it last time?” “Dobby can’t, sir, Dobby can’t, Dobby mustn’t tell!” squealed the elf. “Go home, Harry Potter, go home!” “I’m not going anywhere!” said Harry fiercely. “One of my best friends is Muggle-born; she’ll be first in line if the Chamber really has been opened — ” “Harry Potter risks his own life for his friends!” moaned Dobby in a kind of miserable ecstasy. “So noble! So valiant! But he must save himself, he must, Harry Potter must not — ” Dobby suddenly froze, his bat ears quivering. Harry heard it, too. There were footsteps coming down the passageway outside. “Dobby must go!” breathed the elf, terrified. There was a loud crack, and Harry’s fist was suddenly clenched on thin air. He slumped back into bed, his eyes on the dark doorway to the hospital wing as the footsteps drew nearer. Next moment, Dumbledore was backing into the dormitory, wearing a long woolly dressing gown and a \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Harry looked down at his History of Magic essay, his quill hanging aimlessly from his hand. \n",
      "He couldn't think of how to fill twelve inches of parchment with accounts of Goblin wars. He looked around the common\n",
      "room where a few fifth years remained huddled over their O.W.L notes near the dying fire.” “What do you know about that thing now? About Crouch all those Muggles was the advertions of his house before it would be his information about the castle — ” “Ron!” said Hermione sharply. “I don’t think Harry should be sneaking out of school with Black on the loose — ” “Yeah, I expect that’s what McGonagall will say when I ask for permission,” said Harry bitterly. “But if we’re with him,” said Ron spiritedly to Hermione, “Black wouldn’t dare — ” “Oh, Ron, don’t talk rubbish,” snapped Hermione. “Black’s already murdered a whole bunch of people in the middle of a crowded street. Do you really think he’s going to worry about attacking Harry just because we’re there?” She was fumbling with the straps of Crookshanks’s basket as she spoke. “Don’t let that thing out!” Ron said, but too late; Crookshanks leapt lightly from the basket, stretched, yawned, and sprang onto Ron’s knees; the lump in Ron’s pocket trembled and he shoved Crookshanks angrily away. “Get out of here!” “Ron, don’t!” said Hermione angrily. Ron was about to answer back when Professor Lupin stirred. They watched him apprehensively, but he simply turned his head the other way, mouth slightly open, and slept on. The Hogw\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = \"\"\"He glared at Voldemort, staring into his snake-like eyes. Hooded Death Eaters surriounded them, jeering \n",
    "and laughing as their master taunted and tortured Harry. \"\"\"\n",
    "print(generate(seed))\n",
    "print('-'*100+'\\n')\n",
    "\n",
    "seed = \"\"\"Harry gripped his wand tightly, wondering which spell would come in most useful. \"\"\"\n",
    "print(generate(seed))\n",
    "print('-'*100+'\\n')\n",
    "\n",
    "seed = \"\"\"Harry was growing more and more frustrated by the assignment Snape had set them. How was he supposed to \n",
    "focus when he had a Goblin rebellion, a date, and a summons to the Ministry of Magic to worry about? Absentmindedly\n",
    " chewing his quill, he thought of what he might tell Sirius, and what Sirius might think. \"\"\"\n",
    "print(generate(seed))\n",
    "print('-'*100+'\\n')\n",
    "\n",
    "seed = \"\"\"Harry looked down at his History of Magic essay, his quill hanging aimlessly from his hand. \n",
    "He couldn't think of how to fill twelve inches of parchment with accounts of Goblin wars. He looked around the common\n",
    "room where a few fifth years remained huddled over their O.W.L notes near the dying fire.\"\"\"\n",
    "print(generate(seed))\n",
    "print('-'*100+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1rc1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33626.443449,
   "end_time": "2022-02-23T11:23:15.525736",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-23T02:02:49.082287",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
